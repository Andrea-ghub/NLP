{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DeM_kOB0hdYR"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from torch import tensor\n",
        "import torch.nn.functional as functional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KDugcy8LUQU"
      },
      "source": [
        "### TODO\n",
        "* Sostituire NLLLoss (negative log likelihood loss) con CrossEntropy. Rimuovere LogSoftmax\n",
        "* Allenare word2vec su un file di 30MB preso dal nostro corpus\n",
        "* classe encoder, classe decoder, classe uniti i due insieme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZA2Utqp_Rs1h"
      },
      "outputs": [],
      "source": [
        "# unwanted characters\n",
        "chars = [\".\", \",\", \"'\", \"-\", \";\", \":\", '\"', \"(\", \")\", \".\\n\", \"?\\n\", \"!\\n\"]\n",
        "\n",
        "def stripline(line, array = True ):\n",
        "  \"\"\"\n",
        "  Strip the line from unwanted characters\n",
        "  \"\"\"\n",
        "\n",
        "  line.replace('theyre', 'they are')\n",
        "  line.replace('didnt', 'did not')\n",
        "  line.replace('wasnt', 'was not')\n",
        "\n",
        "  if array:\n",
        "    return np.array([word for word in line.split(' ') if word not in chars])\n",
        "  else:\n",
        "    return [word for word in line.split(' ') if word not in chars]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNSmaJEcLXvc"
      },
      "source": [
        "### Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QcHHryo0LYhr"
      },
      "outputs": [],
      "source": [
        "# # train word2vec\n",
        "# corpus = api.load('text8')\n",
        "# old_model = Word2Vec(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VjOalVC9ulUD"
      },
      "outputs": [],
      "source": [
        "f1 = open(\"test30.txt\", \"r\")\n",
        "lines = f1.readlines()\n",
        "lines = [stripline(line, array = False) for line in lines]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(lines)"
      ],
      "metadata": {
        "id": "SImxjGkaEiJc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_list = [\n",
        "    x\n",
        "    for xs in lines\n",
        "    for x in xs\n",
        "]"
      ],
      "metadata": {
        "id": "dkqy69ZwBIKU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(flat_list)\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ChINj-NBtCt",
        "outputId": "ab92d1d3-830e-4cf1-ccc8-cd314c05b221"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82297"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fc-DtZeLdUn"
      },
      "source": [
        "### Pre-process Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtRQ3JVWLj-e",
        "outputId": "03a68d86-c05b-42f6-8549-6c182d61c986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30241\n"
          ]
        }
      ],
      "source": [
        "# load corpus\n",
        "# f1 = open(\"test30.txt\", \"r\") #text_text.txt\n",
        "# lines = f1.readlines()\n",
        "\n",
        "# end vector\n",
        "end_vec = np.array([52 for _ in range(100)])\n",
        "\n",
        "# min length of lines\n",
        "min_len = 3\n",
        "\n",
        "# vocabulary\n",
        "vocab_index2key = model.wv.index_to_key\n",
        "vocab_key2index = model.wv.key_to_index\n",
        "id = np.identity(len(vocab_index2key)+1) # +1 because of the end_vec\n",
        "\n",
        "print(len(vocab_index2key))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jqaw_RN7LhtA"
      },
      "outputs": [],
      "source": [
        "def word2vec(word):\n",
        "  return model.wv[word]\n",
        "\n",
        "def vec2word(vec):\n",
        "  return model.wv.most_similar(positive=[vec], topn=1)[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cWR7uxVmLlmi"
      },
      "outputs": [],
      "source": [
        "def line2vec(line):\n",
        "  \"\"\"\n",
        "  Convert sentence to array of vectors\n",
        "  \"\"\"\n",
        "\n",
        "  vectors = [word2vec(word) for word in line]\n",
        "  vectors.append(end_vec)\n",
        "\n",
        "  return np.array(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AodOaxo-jt49"
      },
      "outputs": [],
      "source": [
        "def onehot(word):\n",
        "  \"\"\"\n",
        "  One hot encode the words, except for the end word (which doesn't exist anyway)\n",
        "  \"\"\"\n",
        "\n",
        "  index = vocab_key2index[word]\n",
        "\n",
        "  return id[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5s9OeR3CXCuj"
      },
      "outputs": [],
      "source": [
        "def sublines_vecs(vectors):\n",
        "  \"\"\"\n",
        "  Return a sub-sentence and the following word\n",
        "  \"\"\"\n",
        "\n",
        "  start_min = 3\n",
        "\n",
        "  # choose the starting word\n",
        "  starting_word = np.random.randint(start_min, len(vectors)-1) # randint doesn't return the last one\n",
        "\n",
        "  # get the sub line\n",
        "  f_vectors = vectors[starting_word:]\n",
        "\n",
        "  # return one hot encoding of the following words. If one of the following words is the end token, then\n",
        "  # don't use the onehat function, because the vocabulary doesn't have the end token\n",
        "  one_hot_f_vectors = [id[-1] if (f_vector==end_vec).all() else onehot(vec2word(f_vector)) for f_vector in f_vectors]\n",
        "\n",
        "  return vectors[:starting_word], one_hot_f_vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyUqj_TRFY0c"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NgCmXHmZLps9"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.i2h = nn.Linear(self.input_size, self.hidden_size)\n",
        "        self.h2h = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "\n",
        "        self.relu = functional.relu\n",
        "        # self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, input, prev_hidden):\n",
        "        current_hidden = self.relu(self.i2h(input) + self.h2h(prev_hidden))\n",
        "        return current_hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.rand(self.hidden_size) #zeros?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-78u_fTGwYQr"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.i2h = nn.Linear(self.input_size, self.hidden_size)\n",
        "        self.h2h = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.h2o = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.relu = functional.relu #leaky_relu\n",
        "        self.softmax = nn.Softmax(dim=0)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=0)\n",
        "\n",
        "    def forward(self, input, prev_hidden, hiddens_encoder):\n",
        "        # hidden\n",
        "        current_hidden = self.relu(self.i2h(input) + self.h2h(prev_hidden))\n",
        "\n",
        "        # context\n",
        "        scalar_products = tensor([torch.dot(prev_hidden, hidden_enc) for hidden_enc in hiddens_encoder])\n",
        "        alphas = self.softmax(scalar_products)\n",
        "\n",
        "        # weighted average of hiddens with alphas\n",
        "        context = (torch.mul(torch.stack(hiddens_encoder, dim=1), alphas).t()/alphas.sum()).sum(dim=0)\n",
        "\n",
        "        # pg 201 our choice of how to use the context vector\n",
        "        context = self.tanh(context)\n",
        "        current_hidden = context*current_hidden\n",
        "\n",
        "        # produce output\n",
        "        output = self.h2o(current_hidden)\n",
        "        output = self.logsoftmax(output)\n",
        "\n",
        "        return output, current_hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.rand(self.hidden_size) # not zeros due to the scalar product\n",
        "\n",
        "    def initInput(self):\n",
        "        return torch.rand(self.input_size) # zeros?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Abe9pzumwYTP"
      },
      "outputs": [],
      "source": [
        "class GPT1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, lr=0.1):\n",
        "        super(GPT1, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.encoder = Encoder(input_size, hidden_size)\n",
        "        self.decoder = Decoder(input_size, hidden_size, output_size)\n",
        "\n",
        "        self.loss = nn.NLLLoss()\n",
        "        # https://discuss.pytorch.org/t/pytorch-combine-two-models-into-a-single-class-and-access-their-parameters-from-the-parent-class/83000\n",
        "        self.optimizer = optim.Adam(\n",
        "            self.parameters(),\n",
        "            lr=lr)\n",
        "\n",
        "    def forward(self, input_subline, one_hot_f_vectors=None, predict=False):\n",
        "\n",
        "        # unroll encoder\n",
        "        init_hidden_e = self.encoder.initHidden()\n",
        "        hiddens_encoder = [self.encoder(tensor(vec).float(), init_hidden_e) for vec in input_subline]\n",
        "\n",
        "        # unroll decoder\n",
        "        init_hidden_d = self.decoder.initHidden()\n",
        "        init_input_d = self.decoder.initInput()\n",
        "\n",
        "        # predict outputs\n",
        "        decoder_outputs = []\n",
        "\n",
        "        # do\n",
        "        decoder_outputs.append( self.decoder(init_input_d, init_hidden_d, hiddens_encoder) )\n",
        "\n",
        "        # predict\n",
        "        if predict:\n",
        "\n",
        "          while np.argmax(output) != self.output_size:\n",
        "\n",
        "            output, prev_hidden = decoder_outputs[-1]\n",
        "\n",
        "            input = word2vec(vocab_index2key[np.argmax(output)])\n",
        "            decoder_outputs.append( self.decoder(input, prev_hidden, hiddens_encoder) )\n",
        "\n",
        "            if len(decoder_outputs) > 15:\n",
        "              break\n",
        "\n",
        "        # train\n",
        "        else:\n",
        "\n",
        "          for i in range(len(one_hot_f_vectors)-1):\n",
        "\n",
        "            output, prev_hidden = decoder_outputs[-1]\n",
        "\n",
        "            input = word2vec(vocab_index2key[torch.argmax(output).item()])\n",
        "            decoder_outputs.append( self.decoder(tensor(input).float(), prev_hidden, hiddens_encoder) )\n",
        "\n",
        "        # return distributions on the vocabulary\n",
        "        return [decoder_output[0] for decoder_output in decoder_outputs]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_GlCibasCtM"
      },
      "source": [
        "### Test sandbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZteC-BMdLnZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "449e861c-7954-4b1a-ad89-b9c63e83bcb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence:  ['i', 'walked', 'along', 'the', 'empty', 'road', 'alone', 'occasionally', 'waving', 'to', 'passing', 'kids', 'on', 'bikes']\n",
            "Sub sentence:  ['i', 'walked', 'along', 'the', 'empty', 'road', 'alone', 'occasionally']\n",
            "Next word:  waving\n",
            "Next word:  to\n",
            "Next word:  passing\n",
            "Next word:  kids\n",
            "Next word:  on\n",
            "Next word:  bikes\n",
            "Next word:  wampus\n",
            "\n",
            "\n",
            "Sub sentence:  ['i', 'walked', 'along', 'the', 'empty', 'road', 'alone']\n",
            "Next word:  occasionally\n",
            "Next word:  waving\n",
            "Next word:  to\n",
            "Next word:  passing\n",
            "Next word:  kids\n",
            "Next word:  on\n",
            "Next word:  bikes\n",
            "Next word:  wampus\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "line = lines[11]\n",
        "# line = stripline(line)\n",
        "\n",
        "print('Original sentence: ', line)\n",
        "\n",
        "vectors = line2vec(line)\n",
        "\n",
        "for _ in range(2):\n",
        "  sub_vectors, one_hot_f_vectors = sublines_vecs(vectors)\n",
        "\n",
        "  print('Sub sentence: ',[vec2word(vec) for vec in sub_vectors])\n",
        "\n",
        "  for one_hot_f_vector in one_hot_f_vectors:\n",
        "    if np.argmax(one_hot_f_vector) >= len(vocab_index2key):\n",
        "      print('Next word: ', vec2word(end_vec))\n",
        "    else:\n",
        "      print('Next word: ', vocab_index2key[np.argmax(one_hot_f_vector)])\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "3keSRJ0_Bd9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96bb2b87-45e9-4d79-e814-89eb7b9790ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['none', 'traversed', 'dumpster', 'aiden']\n"
          ]
        }
      ],
      "source": [
        "gpt = GPT1(100, 300, len(id))\n",
        "\n",
        "logprobs = gpt(sub_vectors, one_hot_f_vectors)\n",
        "words = [vocab_index2key[torch.argmax(logprob).item()] for logprob in logprobs]\n",
        "\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "TPPAPD6hDtwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e7b1f1-175d-48fc-c1ba-a55bb8e37e86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key not present in vocab.\n",
            "tensor(0.1116, grad_fn=<SelectBackward0>)\n",
            "tensor(-0.1222, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(0.1787, grad_fn=<SelectBackward0>)\n",
            "tensor(-0.1892, grad_fn=<SelectBackward0>)\n",
            "tensor(0.2305, grad_fn=<SelectBackward0>)\n",
            "tensor(-0.2410, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(0.2729, grad_fn=<SelectBackward0>)\n",
            "tensor(-0.2834, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(0.3087, grad_fn=<SelectBackward0>)\n",
            "tensor(-0.3193, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(0.3396, grad_fn=<SelectBackward0>)\n",
            "tensor(-0.3502, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(0.3666, grad_fn=<SelectBackward0>)\n",
            "tensor(-0.3772, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(0.3904, grad_fn=<SelectBackward0>)\n",
            "tensor(-0.4009, grad_fn=<SelectBackward0>)\n",
            "tensor(0.4116, grad_fn=<SelectBackward0>)\n",
            "tensor(-0.4221, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(0.4304, grad_fn=<SelectBackward0>)\n",
            "tensor(-0.4409, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(0.4473, grad_fn=<SelectBackward0>)\n",
            "tensor(-0.4578, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "key not present in vocab.\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n",
            "tensor(nan, grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "params_e = []\n",
        "params_d = []\n",
        "losses = []\n",
        "\n",
        "for epoch in range(1, 200):\n",
        "\n",
        "    pred_words = []\n",
        "    true_words = []\n",
        "\n",
        "    dim_batch = 8\n",
        "    # batch of random lines\n",
        "    batch = [lines[i] for i in np.random.randint(0, len(lines), dim_batch)]\n",
        "    # batch = [stripline(lines[11]), stripline(lines[11])]\n",
        "\n",
        "    for line in batch:\n",
        "\n",
        "        # convert to vector\n",
        "        try:\n",
        "          vectors = line2vec(line)\n",
        "          # divide into sub_line and labels\n",
        "          sub_vectors, one_hot_f_vectors = sublines_vecs(vectors)\n",
        "        except:print(\"key not present in vocab.\")\n",
        "\n",
        "        # gpt predicts\n",
        "        logprobs = gpt(sub_vectors, one_hot_f_vectors)\n",
        "\n",
        "        # out assumption that the prob(word1 & ... & wordn) = prob(word1)*...*prob(wordn)\n",
        "        # --> log(prob(word1 & ... & wordn)) = sum log\n",
        "        # --> sum on batch and sum on words is the same\n",
        "        for logprob,one_hot_f_vector in zip(logprobs, one_hot_f_vectors):\n",
        "          pred_words.append(logprob)\n",
        "          true_words.append(tensor(one_hot_f_vector))\n",
        "\n",
        "    # backpropagation\n",
        "    gpt.zero_grad()\n",
        "\n",
        "    pred_words = torch.stack(pred_words)\n",
        "    true_words = torch.stack(true_words)\n",
        "\n",
        "    loss = gpt.loss(pred_words[0], true_words[0].long())\n",
        "    loss.backward()\n",
        "    losses.append(loss)\n",
        "    gpt.optimizer.step()\n",
        "\n",
        "    params_e.append([p for p in gpt.encoder.parameters()])\n",
        "    params_d.append([p for p in gpt.decoder.parameters()])\n",
        "\n",
        "    # print(params_d[-1][0][0][0])\n",
        "    # print(params_e[-1][0][0][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs = gpt(sub_vectors, one_hot_f_vectors)\n",
        "words = [vocab_index2key[torch.argmax(logprob).item()] for logprob in logprobs]\n",
        "\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKhtY3_D5CX4",
        "outputId": "ff4f03c0-e62d-4015-ecfa-574614935cd0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'the']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([los.detach().numpy() for los in losses])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "_dkk9lsVFk2X",
        "outputId": "90e8c2e9-3c04-4c60-921b-02f9056d485f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7867d736f070>]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QjL1rLF9oUcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "c4b9711a-79a4-4c17-d62c-589c1a3c6f20"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-20-d7937bb5f84c>, line 33)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-d7937bb5f84c>\"\u001b[0;36m, line \u001b[0;32m33\u001b[0m\n\u001b[0;31m    all_losses.append(mean_loss.detach\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ],
      "source": [
        "out = torch.stack(out)\n",
        "out = torch.reshape(out, (batch, len(category_tensor)))\n",
        "true_categories = torch.stack(true_categories)\n",
        "loss = backpropagation(out, true_categories)\n",
        "\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    out = []\n",
        "    true_categories = []\n",
        "    for j in range(batch):\n",
        "        category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "        output = predict(line_tensor)\n",
        "\n",
        "        out.append(output)\n",
        "        true_categories.append(category_tensor[0])\n",
        "\n",
        "    out = torch.stack(out)\n",
        "    out = torch.reshape(out, (batch, len(category_tensor)))\n",
        "    true_categories = torch.stack(true_categories)\n",
        "    loss = backpropagation(out, true_categories)\n",
        "\n",
        "    current_loss += loss\n",
        "\n",
        "    # Print ``iter`` number, loss, name and guess\n",
        "    if iter % print_every == 0:\n",
        "        guess, guess_i = categoryFromOutput(output)\n",
        "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
        "\n",
        "    # Add current loss avg to list of losses\n",
        "    if iter % plot_every == 0:\n",
        "        mean_loss = current_loss / plot_every\n",
        "        all_losses.append(mean_loss.detach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iDoiEKVvi6x"
      },
      "outputs": [],
      "source": [
        "# BATCH"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}